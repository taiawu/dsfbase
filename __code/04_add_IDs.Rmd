---
title: "R Notebook"
output: html_notebook
---

Read in the tidied DSFbase curves and add IDs
Plot, and edit assignments

```{r}
library(glue)
library(tidyverse)
library(fs)
library(testthat)
source("R/collect_dsf_data.R")
```

Read in each screen, add a unique ID, and add to a 
```{r}
ID_and_combine <- 
  function(DSFBASE_DIR = "../02_aggregated_data/", 
           .use_cols = c("id", "subset", "protein", "well", "variable", "Temperature", "value"),
           .test_subset = TRUE,
           .save_output_to = "../03_combined_data",
           .save_output = TRUE,
           .return_output = FALSE){
  
  tally_dsfbase(DSFBASE_DIR)
  all_dirs <- fs::dir_ls(DSFBASE_DIR, recurse = 1, regexp = ".rds")
  
  if(.test_subset){
    all_dirs <- all_dirs[1:10]
  }
  
   # initialize tibbles
   id_key <- tibble(directory = character(),
                     protein = character(),
                    variable = character(),
                    id = character())
   
   dsfbase <- tibble(id = character(),
                    protein = character(),
                    subset = character(),
                    Temperature = numeric(),
                    value = numeric())
   
   failed_dirs <- c()
    
   for(directory in all_dirs) {
     print(glue("----Reading directory: {directory}"))
     
     dsf <- 
       read_rds(directory) |> 
       select(all_of(.use_cols)) |> 
       select(-id) # going to overwrite this
    
     ###------ add individual ids
    .id_num <- nrow(id_key)
    .subset <- unique(dsf$subset)
    .n_datasets <- n_distinct(dsf$variable)
    #print(glue("Enumerating IDs for {.n_datasets} datasets starting from: {.id_num}"))
    
    id_int <- tibble(directory = character(),
                    variable = character(),
                    id = character())
    
      for(variable in unique(dsf$variable)) {
            .id_num <- .id_num + 1
            
            id_int <- 
              id_int |> 
              add_row("directory" = directory,
                      "variable" = variable,
                      "id" = make_ID(.ID_num = .id_num, .subset = .subset))
 
      }

     
    ##
     dsfbase_int <-
       dsf |>
       left_join(id_int, by = join_by(variable)) 
     # |>
     #   select(id, subset, Temperature, value)

     id_key <- bind_rows(id_key, id_int)
     dsfbase <- bind_rows(dsfbase, dsfbase_int)
     
   }
   
   dsfbase <- dsfbase |> 
     mutate(subset = factor(subset, levels = c("SYPRO_canon", "canon", "SYPRO_noncanon", "noncanon", "gotcha"))) |> 
     group_by(id) |> 
     mutate(value_norm = scales::rescale(value, c(0,1))) |> 
     ungroup()
   
   # save dsfbase
   if(.save_output){
       # save id map
   id_save <- glue("{.save_output_to}/dsfbase_id_map.rds")
   print(glue("saving id map to: {id_save}"))
   write_rds(x = id_key, 
             id_save)
   
   dsfbase_save <- glue("{.save_output_to}/dsfbase.rds")
   print(glue("saving dsfbase to: {dsfbase_save}"))
   
    write_rds(x = dsfbase, 
             dsfbase_save) 
   }

   if(.return_output){
     out <- list("id_key" = id_key,
                  "dsfbase" = dsfbase)
   }

  }

tally_dsfbase()

```

Write combined DSFbase files 
```{r}
ID_and_combine(.return_output = FALSE, .save_output = TRUE, .test_subset = FALSE)
```

Read combined dsfbase files
```{r}
id_map <- read_rds("../03_combined_data/dsfbase_id_map.rds")
dsfbase <- read_rds("../03_combined_data/dsfbase.rds")
```

Save individual dsdfbase files
```{r}
dsfbase |>  head()

dsfbase_to_csv <- function(dsfbase, 
                           by_subset = TRUE,
                           value_col = "value_norm",
                           .save_to = "../03_combined_data/by_subset/",
                           .save_full = TRUE,
                           .save_subset = TRUE,
                           ...){
  
  subsets <- as.character(sort(unique(dsfbase$subset)))
  
  dsfbase_l <- dsfbase |> 
    arrange(subset) |> 
    group_by(subset) |> 
    group_split() 
  
  names(dsfbase_l) <- subsets
  
  save_paths <- glue()
  
  wide_l <- lapply(dsfbase_l, dsfbase_wide, value_col = value_col)
  

    if(.save_full) {
      dsfbase_wide <- dsfbase |> dsfbase_wide(value_col = value_col)
      n_curves <- ncol(dsfbase_wide) - 1
      save_name <- glue("{.save_to}dsfbase_all_{n_curves}_curves.csv")
      write_csv(x = dsfbase_wide, save_name)
    }
    
    if(.save_subset){
      i <- 0
    for(.subset in subsets){
       i <- i + 1
      dsf <- wide_l[[.subset]]
      n_curves <- ncol(dsf) - 1
      save_name <- glue("{.save_to}dsfbase_subset_{i}_{.subset}_{n_curves}_curves.csv")
      write_csv(x = dsf, save_name)
  }
    }
  
}

dsf_wide <- dsfbase_to_csv(dsfbase)



dsfbase |> filter(subset == "canon") |>  head()

dsfbase_wide <- function(dsf, value_col, ...){
  dsf_wide <- dsf |> 
  select(all_of(c("Temperature", "id", value_col))) |> 
  pivot_wider(id_cols = "Temperature", names_from = "id", values_from = value_col)
}
```

Format for easy .csv saving
```{r}
dsfbase_wide <- dsfbase |> 
  select(Temperature, id, value) |> 
  pivot_wider(id_cols = Temperature, names_from = id, values_from = value)

dsfbase_wide |> write_csv(x = _, file = "../03_combined_data/dsfbase.csv")

dsfbase_wide |>  str()
```



Want to combine the ID map with more useful info about the datasets
```{r}
# how many different proteins total?

# how many different dyes?

# how many different thermocycling conditions?

# how many different instruments?

# what date range? 

id_map
```



##### scratch work below this line



Function to generate curve IDs
```{r}
make_ID <- 
  function(.subset,
           .ID_num,
           dsfbase_version = 1,
           ...
           ){
    
    ID <- stringr::str_pad(.ID_num, 6, pad = "0")

    glue("DSFbase00{dsfbase_version}_{.subset}_ID{ID}")
    
  }

make_ID("canon", 1)

```

Read in raw data
```{r}
# from dye screens
dye <- vroom::vroom("../00_raw_inputs/data_S3_dye_screen_results_raw.txt")

# from SYPRO
sypro <- read
```

```{r}
trim <-
  raw |> 
  select(variable, Temperature, value) |> 
  pivot_wider(id_cols = Temperature, 
              names_from = variable, 
              values_from = value)
```

Generate the ID map
This will almost certainly get re-generated in the end, 
oncewe decide how we want to order the data to make it more user-friendly
e.g. the first 500 are all SYPRO, the next 5,000 are with-protein hits, sensitives, the last bunch are EBPs...
```{r}
ID_map <- 
  tibble(original = names(trim)) |> 
  filter(original != "Temperature") |> 
  mutate(ID = make_IDS(original, source_id = 2)) |> 
  relocate(ID)

ID_map
```

Add IDs as names for each tibble
```{r}
final <- trim |> 
  set_names(c("Temperature", ID_map$ID))
```

Save the output file
```{r}
# 175 MB
final |> vroom::vroom_write("../01_intermediate_outputs/dye_screens_indexed.txt")
ID_map |> write_rds("../01_intermediate_outputs/dye_screens_index_map.rds")
```







Possibly or likely duplicated code -- fold in above in you want to

##
Function to generate curve IDs
```{r}
make_IDS <- 
  function(input_vars, 
           dsfbase_version = 1,
           source_id = 1,
           ID_start = 1){

    
  out <- tibble(orig = input_vars,
      header = glue::glue("DSF00{dsfbase_version}_S0{source_id}")) |>
      mutate(
             id = paste0(header, "_", "ID",
                                         stringr::str_pad(row_number() + ID_start - 1, # the curve number
                                                          6, # to six places
                                                          pad = "0")) # left-pad zeroes
      )

    
  out$id
  }

make_IDS(c("two", "zed"))
```

Read in raw data
```{r}
# from dye screens
dye <- vroom::vroom("../00_raw_inputs/data_S3_dye_screen_results_raw.txt")

# from SYPRO
sypro <- read
```

```{r}
trim <-
  raw |> 
  select(variable, Temperature, value) |> 
  pivot_wider(id_cols = Temperature, 
              names_from = variable, 
              values_from = value)
```

Generate the ID map
This will almost certainly get re-generated in the end, 
oncewe decide how we want to order the data to make it more user-friendly
e.g. the first 500 are all SYPRO, the next 5,000 are with-protein hits, sensitives, the last bunch are EBPs...
```{r}
ID_map <- 
  tibble(original = names(trim)) |> 
  filter(original != "Temperature") |> 
  mutate(ID = make_IDS(original, source_id = 2)) |> 
  relocate(ID)

ID_map
```

Add IDs as names for each tibble
```{r}
final <- trim |> 
  set_names(c("Temperature", ID_map$ID))
```

Save the output file
```{r}
# 175 MB
final |> vroom::vroom_write("../01_intermediate_outputs/dye_screens_indexed.txt")
ID_map |> write_rds("../01_intermediate_outputs/dye_screens_index_map.rds")
```




